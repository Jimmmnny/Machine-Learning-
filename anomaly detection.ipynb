{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38126785-df06-4e5f-8510-8e9bbc12792f",
   "metadata": {},
   "source": [
    "# Local Outlier Factor(LOF) and  Isolation Forest (IF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4791ab-d681-4178-9edb-0a301828775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed11c1c-84ea-47ac-be7f-c0f055de4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('a.csv')\n",
    "df.shape\n",
    "df.columns\n",
    "df.describe\n",
    "df.isnull().any()#.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a64a4-0439-4eec-818c-553c86d14996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the sample distribution\n",
    "sample = df.sample(frac=0.3,random_state=2000) #use 30% of dataset for checking\n",
    "fraud = sample[sample['class'] == 1]\n",
    "valid = sample[sample['class'] == 0]\n",
    "\n",
    "outlier_fraction = (len(fraud)/float(len(valid)))\n",
    "print('Outlier_fraction :{}%'.format(outlier_fraction*100)) #fraud over valid \n",
    "print('Valid transactions:{}'.format(len(sample[sample['class']==0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7f262-243d-48f4-899f-e01b9aeeba38",
   "metadata": {},
   "source": [
    "## data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff146552-4e11-4218-bcca-2b18b426d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3c362-a2ef-41bd-aaaa-bde6b3fe7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "sns.heatmap(corrmat,vamx=.6, square= True) #vmax is the max and min value you want to have for the scale \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a485059-8656-486f-880d-55577d99e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd330700-414a-4527-8813-4ad1c78f8e0a",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975abcc-3fe6-45fa-a7c2-1f36994ce735",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = corrmat.keys()\n",
    "cols_to_keep = []\n",
    "\n",
    "for i in range(len(corrmat)):\n",
    "    if abs(corrmat['class'][i])>0.01:\n",
    "        cols_to_keep.append(cols[i])\n",
    "\n",
    "len(cols_to_keep)\n",
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3c4da-a085-48a1-9b64-eac08b699757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 'Class' columnn from the features list, as it is the variable we wish to predict\n",
    "cols = cols_to_keep[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda77a0-31a5-423c-ab97-c7eb9805d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[cols]\n",
    "target = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed995f-77f7-444e-b974-2cb774161a22",
   "metadata": {},
   "source": [
    "## model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a968a-156c-4a57-a153-4b52bf5ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define random state\n",
    "state = 2000\n",
    "\n",
    "#define outlier detection tools to be compared\n",
    "classfiers = {\n",
    "    #isolate forest is unsuprvised learning method \n",
    "    'IF' : IsolationForest(max_samples = len(features),\n",
    "                           contamination = outlier_fraction,\n",
    "                           random_state = state),\n",
    "    'LOF' : LocalOutlierFactor(\n",
    "        n_neighbors = 20,\n",
    "        contamination = outlier_fraction\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34370313-ca8f-41e6-88c6-39c8673b1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping the train, test split step since we wish the model to overfit on these features and learn\n",
    "#a mathematical function to map the features \n",
    "\n",
    "n_outliers = len(fraud)\n",
    "\n",
    "for i, (clf_name,clf) in enumerate(classfiers.items()):\n",
    "    if clf_name == 'LOF':\n",
    "        y_pred = clf.fit_predict(features)\n",
    "        scores_pred = clf.negative_outlier_factor_\n",
    "\n",
    "    else:\n",
    "        clt.fit(features)\n",
    "        scores_pred = clf.decision_function(features)\n",
    "        y_pred = clf.predict(features)\n",
    "\n",
    "    #reshape the predcition values to 0 for valid, 1 for fraud \n",
    "    y_pred[y_pred==1] ==0\n",
    "    y_pred[y_pred==-1] == 1\n",
    "\n",
    "    n_errors = (y_pred != target.sum()\n",
    "\n",
    "    # Run classification metrics\n",
    "    print('Classifier {0}: \\nNumber of Errors: {1}'.format(clf_name, n_errors))\n",
    "    print('Accuracy: {0}%\\n'.format(accuracy_score(target, y_pred)*100))\n",
    "    print(classification_report(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7f743-1704-4245-9a91-a28dbdf36d7e",
   "metadata": {},
   "source": [
    "classifiers.items()：这个方法返回一个包含字典中所有键值对的迭代器。每个元素都是一个包含键和值的元组（tuple），例如：('IF', IsolationForest(max_samples = len(features),\n",
    "                           contamination = outlier_fraction,\n",
    "                           random_state = state))。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e4ca3-821e-487a-98dc-e0a6ee3dc090",
   "metadata": {},
   "source": [
    "enumerate 是一个内置函数，用于将一个可迭代的数据对象（如列表、元组、字符串等）组合为一个索引序列，同时列出数据和数据下标。在这里，enumerate 作用于 classifiers.items() 的结果上，这意味着它会生成一系列带有索引的元组，每个元组的第一个元素是索引（从0开始），第二个元素是来自 classifiers.items() 的键值对元组。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82a925-790a-4c07-ad3f-388d4b5ebeee",
   "metadata": {},
   "source": [
    "(i, (clf_name, clf))：这是一个解包表达式，用于在循环中提取索引和键值对。i 是索引，clf_name 是分类器的名称（字典的键），clf 是分类器实例本身（字典的值）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0ce11-59ba-4c5a-9793-3b2a9a932f79",
   "metadata": {},
   "source": [
    "# Gaussian distribution & Multivairate Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dad503e-835f-4841-a68d-5a958d9da598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f7473-361d-4f18-a079-2d5a7a81a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['1','b','c','d']\n",
    "detection_data = df[cols]\n",
    "\n",
    "#Standardization \n",
    "from sklearn.preprocessing import StandarScaler\n",
    "\n",
    "scaler = StandarScaler()\n",
    "detection_data_scaled = scaler.fit_transform(decetion_data)\n",
    "\n",
    "#Mean and coveriance\n",
    "mu =np.mean(detection_data_scaled,axis=0)\n",
    "cov = np.cov(detection_data_scaled,rowvar = False)\n",
    "\n",
    "#Multivirate Gaussian distribution model\n",
    "model = multivariate_normal(mean = mu, cov = cov, allow_singular = True)\n",
    "\n",
    "#Comput P-value\n",
    "p_value = model.pdf(detection_data_scaled)\n",
    "#treshold \n",
    "threshold = np.percentile(p_values,1) #set 1% as the treshold \n",
    "#mark outliers \n",
    "outliers = p_values< threshold \n",
    "\n",
    "#result \n",
    "detection_data['outlier'] = outliers \n",
    "detection_data[detection_data['outlier'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ccd90-e27b-485a-b63b-80697ebab773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#details \n",
    "detection_data[detection_data['outlier']==True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12249a05-d8c6-4082-84f0-ce29ed2f5855",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cffcb-b6b8-4394-ac23-32365855b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "anomalies = detection_data[detection_data['outlier'] == True]\n",
    "\n",
    "scaler = StandarScaler()\n",
    "scaled_data = scaler.fit_transform(anomalies[cols])\n",
    "\n",
    "#PCA\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "#Cumulative variance ratio\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "#visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,len(cumulative_variance_ratio) +1),cumulative_variance_ratio,marker = 'o')\n",
    "plt.title('Cumulative Explained Variance Ratio by Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ab4c6-e688-4c72-ad35-cacb9db2448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of components is 3\n",
    "pca = PCA(n_components=3)\n",
    "principal_components = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8867c5-bb5b-4193-be9a-a9b7fd448755",
   "metadata": {},
   "source": [
    "### clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5411e-44bf-4e9c-9c86-a6038ee0327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "#ELBOW\n",
    "sse = []\n",
    "k_range = range(1,11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_cluster = k, random_state = 2000)\n",
    "    kmeans.fit(principal_components)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "#visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_range,see,marker ='o')\n",
    "plt.title('Elbow method for optimal K')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Errors(SSE)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadae2c8-b547-4e7c-b81a-8a7135bb4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 3\n",
    "kmeans = KMeans(n_clusters = optimal_k,random_state=2000)\n",
    "anomlies['cluster'] = kmeans.fit_predict(principal_components)\n",
    "\n",
    "#Visualization \n",
    "plt.figure(figsize = (10,6))\n",
    "sns.scatterplot(data=pca_df,x = 'PC1', y = 'PC2', hue = 'cluster')\n",
    "plt.title('Kmeans clustering of PCA transformed Anomalies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ae9f3-966a-4d54-8b8c-6e38b2bbf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheack points data in each clusters\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = anomalies[anomalies['cluster'] == cluster]\n",
    "    print(f\"Cluster {cluster} data points:\")\n",
    "    print(cluster_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d5248-e19c-4e35-beff-a30f50193767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discribe of each cluster\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = anomalies[anomalies['cluster'] == cluster]\n",
    "    cluster_mean = cluster_data[columns].mean()\n",
    "    cluster_std = cluster_data[columns].std()\n",
    "    print(f\"Cluster {cluster} mean values:\")\n",
    "    print(cluster_mean)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Cluster {cluster} standard deviation values:\")\n",
    "    print(cluster_std)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c249fb-2963-4d59-bc24-12b6cb2c001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with the normal data points \n",
    "normal_data = detection_data[detection_data['outlier'] ==False]\n",
    "\n",
    "normal_mean = normal_data[columns].mean()\n",
    "normal_std = normal_data[columns].std()\n",
    "\n",
    "print(f\"Normal mean values:\")\n",
    "print(normal_mean)\n",
    "print(\"\\n\")\n",
    "print(f\"Normal standard deviation values:\")\n",
    "print(normal_std)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf430b7-6e77-4ec1-8c14-15f7f5a97c01",
   "metadata": {},
   "source": [
    "# Seasonal and Trend decomposition using Loess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd99f68-1787-4656-abef-6ec8ebb45df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['kw'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acb354-7b7f-406b-98d4-4010a163bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "sns.barplot(x=df.index, y = df['kw'])\n",
    "plt.title('Total Hourly Consumption by Hour')\n",
    "plt.xlabel('Hour of day')\n",
    "plt.ylabel('Total Hourly consumption(KW)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cb375-6f1b-4c33-beab-57cca0372069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "from itertools import product\n",
    "\n",
    "seasonal_options = [7,13,23] #smoothness of the seasonal component\n",
    "period_options = [24] #24hours\n",
    "\n",
    "#initialize best parameters and residual \n",
    "best_parameters = None\n",
    "min_residual_var=  np.inf\n",
    "\n",
    "#loop\n",
    "for seasonal, period in product(seasonal_options, period_options):\n",
    "    stl = STL(df['kw'],seasonal = seasonal, period = period)\n",
    "    result = stl.fit()\n",
    "\n",
    "    #vairance\n",
    "    residual_var = result.resid.var()\n",
    "\n",
    "    #update\n",
    "    if residual_var < min_residual_var:\n",
    "        min_residual_var= residual_var\n",
    "        best_parameters = (seasonal,period)\n",
    "\n",
    "best_parametsers, min_residual_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa31d86-8eda-413d-b29a-5d467ed03633",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl = STL(df['kW'], seasonal=7, period=24)  \n",
    "result = stl.fit()\n",
    "\n",
    "# Get trend, seasonal and residual\n",
    "trend = result.trend\n",
    "seasonal = result.seasonal\n",
    "residual = result.resid\n",
    "\n",
    "# Anomaly: Residual > 2 * std\n",
    "residual_std = residual.std()\n",
    "anomalies = residual[abs(residual) > 2 * residual_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a321500-e215-45c0-9a12-872765229a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trend'] = trend \n",
    "df['seasonal'] = seasonal \n",
    "df['residual'] = residual \n",
    "df['is_anomaly'] = df['residual'].apply(lambda x: 'Yes' if abs(x)>2*residual_std else 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f15b3-7baf-422f-9bcd-e20e3602fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Initial data\n",
    "plt.subplot(411)\n",
    "plt.plot(df.index, df['kW'], label='Original', color='blue')\n",
    "plt.title('Original Data')\n",
    "plt.legend()\n",
    "\n",
    "# Trend component\n",
    "plt.subplot(412)\n",
    "plt.plot(df.index, df['trend'], label='Trend', color='red')\n",
    "plt.title('Trend Component')\n",
    "plt.legend()\n",
    "\n",
    "# Seasonal component\n",
    "plt.subplot(413)\n",
    "plt.plot(df.index, df['seasonal'], label='Seasonal', color='green')\n",
    "plt.title('Seasonal Component')\n",
    "plt.legend()\n",
    "\n",
    "# Residual component\n",
    "plt.subplot(414)\n",
    "plt.plot(df.index, df['residual'], label='Residual', color='magenta')\n",
    "plt.title('Residual Component')\n",
    "plt.legend()\n",
    "\n",
    "# Mark anomaly data\n",
    "for time_point in anomalies.index:\n",
    "    plt.axvline(x=time_point, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74780f-950e-4ea5-bfb1-a77be58104ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data = df[df['is_anomaly'] == 'Yes']\n",
    "anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae4b18-8bd4-4153-a83a-4550d2ce6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(131)\n",
    "sns.countplot(x=anomaly_data['hour'], data=anomaly_data)\n",
    "plt.title('Hourly Distribution of Anomalies')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Count of Anomalies')\n",
    "\n",
    "# monthly\n",
    "plt.subplot(132)\n",
    "sns.countplot(x=anomaly_data['month'], data=anomaly_data)\n",
    "plt.title('Monthly Distribution of Anomalies')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count of Anomalies')\n",
    "\n",
    "# weekday\n",
    "plt.subplot(133)\n",
    "sns.countplot(x=anomaly_data['weekday'], data=anomaly_data)\n",
    "plt.title('Weekday Distribution of Anomalies')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Count of Anomalies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
